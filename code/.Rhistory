tukey
sov(waste~supplier, newdata)
aov(waste~supplier, newdata)
res = aov(waste~supplier, newdata)
res$qr
res$contrasts
summary(res)
print(res)
?pairwise.t.test
pairwise.t.test(newdata$waste, newdata$supplier, p.adjust.method = "none")
pairwise.t.test(newdata$waste, newdata$supplier, p.adjust.method = "none")
pairwise.t.test(newdata$waste, newdata$supplier, p.adjust.method = "bonferroni")
pairwise.t.test(newdata$waste, newdata$supplier, p.adjust.method = "BH")
pairwise.t.test(newdata$waste, newdata$supplier, p.adjust.method = "BY")
Of course, the obvious selection will be supplier 1, as it produces the least waste. However, if there were difference in the cost of the suppliers with the first the most expensive and the last cheapest, We could consider choosing supplier 3 or 4 or 5, depending on the trade-off between the cost and the amount of waste. The choice will depend on how much the cost increases for each suppliers, if the difference between each supplier is significant, the obvious choice will be choosing supplier 5, since the cost will cover for the waste. However, if the difference in cost is not too much, it will be reasonable to choose supplier 3, as it significantly reduces the waste compared to supplier 5, but not increases the waste significantly compared to supplier 1.
fat
df = fat[, -c(1,3)]
df
n = nrow(df)
5%2
5//2
5/2
5%2
5/%/2
5%%2
10%%7
535345634%%10
train_df = df[(1:n)%%10!=0,]
test_df = df[(1:n)%%10==0,]
moda = lm(siri~., data = train_df)
regsubsets(siri~., data =train_df)
?regsubsets
library(leaps)
res = regsubsets(siri~., data =train_df)
t = summary(res)
n = nrow(train_df)
aic2 = n * log(t$rss/n) + (1:(ncol(stackloss)-1))*2
aic2 = n * log(t$rss/n) + (1:(ncol(train_df)-1))*2
n = nrow(train_df)
aic2 = n * log(t$rss/n) + (1:(ncol(train_df)-1))*2
log(t$rss/n)
(1:(ncol(train_df)-1))
ncol(train_df)
t
?regsubsets
res = regsubsets(siri~., data =train_df, nvmax = 15)
t = summary(res)
n = nrow(train_df)
aic2 = n * log(t$rss/n) + (1:(ncol(train_df)-1))*2
aic2
aic = n * log(t$rss/n) + (1:(ncol(train_df)-1))*2
which.min(aic)
t
t$outmat
t$outmat[which.min(aic),]
t$which
t$obj
t$which[which.min(aic),]
modb = lm(siri~weight+adipos+free+chest+abdom+
thigh+knee+ankle+biceps+forearm, data = train_df)
install.packageS('pls')
install.packages('pls')
library(pls)
pcr(siri~., data = train_df)
modc = pcr(siri~., data = train_df)
modc
summary(modc)
?pcr
modc = pcr(siri~., data = train_df, scale = T)
summary(modc)
summary(lm(waste~supplier),denim)
summary(lm(waste~supplier),data = denim)
denim
summary(lm(waste~supplier,data = denim))
?pairwise.t.test
pairwise.t.test(newdata$waste, newdata$supplier, p.adjust.method = "none", pool.sd = F)
summary(lm(waste~supplier,data = newdata))
t.test(newdata$waste[which(newdata$supplier==1),],
newdata$waste[which(newdata$supplier==2),])
which(newdata$supplier==1)
t.test(newdata$waste[which(newdata$supplier==1)],
newdata$waste[which(newdata$supplier==2)])
?t.test
lm(waste~relevel(supplier, ref=2), data = newdata)
res = lm(waste~relevel(supplier, ref=2), data = newdata)
summary(res)
?lm.ridge
summary(res)$coefficients
summary(res)$coefficients[,4]
summary(res)$coefficients[2:5,4]
pvs = matrix(0,nrow = 5,5)
for(i in 1:5){
res = lm(waste~relevel(supplier, ref=i), data = newdata)
pvs[-i,i] = summary(res)$coefficients[2:5,4]
}
pvs
pvec = c(pvs[2:5,1], pvs[3:5,1], pvs[4:5,1], pvs[5,1])
pvec
names(pvec) = c('1-2', '1-3', '1-4', '1-5', '2-3',
'2-4', '2-5', '3-4', '3-5', '4-5')
pvec
p.adjust(pvec, method = 'bonferroni')
p.adjust(pvec, method = 'BH')
p.adjust(pvec, method = 'BY')
pvec = c(pvs[2:5,1], pvs[3:5,2], pvs[4:5,3], pvs[5,4])
names(pvec) = c('1-2', '1-3', '1-4', '1-5', '2-3',
'2-4', '2-5', '3-4', '3-5', '4-5')
p.adjust(pvec, method = 'bonferroni')
p.adjust(pvec, method = 'BH')
p.adjust(pvec, method = 'BY')
which(p.adjust(pvec,method = 'bonferroni')<0.05)
p_bonf[p_bonf<0.05]
p_bonf = p.adjust(pvec, method = 'bonferroni')
p_bonf[p_bonf<0.1]
p_bh = p.adjust(pvec, method = 'BH')
p_bh[p_bh<0.1]
p_by = p.adjust(pvec, method = 'BY')
p_by[p_by<0.1]
rmse = function(x,y){sqrt(mean((x-y)^2))}
?RMSEP
?pcr
?pcr
modpcr = pcr(siri~., data = train_df, validation = 'CV')
summary(modpcr)
modpcr$model
modpcr$scores
View(modpcr)
respcr = summary(modpcr)
respcr = summary(modpcr)
respcr = summary(modpcr)
modpcr$validation
pcrmse = RMSEP(modpcr)
pcrmse
summary(modpcr)
pcrmse
?RMSEP
pcrmse[,which.min(pcrmse[2,])]
pcrmse[2,]
pcrmse
pcrmse$val
pcrmse[,which.min(pcrmse$val[2,])]
pcrmse$val[2,]
pcrmse$val[1,]
pcrmse$val[1,1]
pcrmse$val[1,1,]
summary(modpcr)
pcrmse[,which.min(pcrmse$val[1,1,])]
which.min(pcrmse$val[1,1,])
pairwise.t.test(newdata$waste, newdata$supplier, method = 'BH')
p_bh
p_hy
p_by
pairwise.t.test(newdata$waste, newdata$supplier, method = 'BY')
modc = pcr(siri~. , data = train_df, ncomp = 7)
?pcr
modpls = plsr(siri~., data = train_df, validation = 'CV')
summary(modpls)
pcrmse = RMSEP(modplsr)
pcrmse = RMSEP(modpls)
which.min(plsmse$val[1,1,])
which.min(plsmse$val[1,1,])
plsmse = RMSEP(modpls)
which.min(plsmse$val[1,1,])
pvs
pvec
p_bonf
pairwise.t.test(newdata$waste, newdata$supplier, method = 'bonferroni')
pairwise.t.test(newdata$waste, newdata$supplier, method = 'BY')
p_by
newdata
?pairwise.t.test
p_by = p.adjust(pvec, p.adjust.method = 'BY')
p_by[p_by<0.1]
p_bonf = p.adjust(pvec, p.adjust = 'bonferroni')
p_bonf[p_bonf<0.1]
pairwise.t.test(newdata$waste, newdata$supplier, p.adjust.method = 'BY')
pairwise.t.test(newdata$waste, newdata$supplier, p.adjust.method = 'bonferroni')
pairwise.t.test(newdata$waste, newdata$supplier, p.adjust.method = 'BH')
pairwise.t.test(newdata$waste, newdata$supplier, p.adjust.method = 'BY')
which.min(plsmse$val[1,1,])
modd = pcr(siri~. , data = train_df, ncomp = 4)
library(MASS)
modrid = lm.ridge(siri~. data = train_df, lambda = seq(0, 1, len= 20))
modrid = lm.ridge(siri~. ,data = train_df, lambda = seq(0, 1, len= 20))
plot(modrid)
modrid = lm.ridge(siri~. ,data = train_df, lambda = seq(0, 100, len= 20))
plot(modrid)
modrid = lm.ridge(siri~. ,data = train_df, lambda = seq(0, 10, len= 20))
plot(modrid)
modrid = lm.ridge(siri~. ,data = train_df, lambda = seq(0, 100, len= 50))
plot(modrid)
?lm.ridge
?lm.ridge
modrid$GCV
plot(modrid$GCV)
modrid = lm.ridge(siri~. ,data = train_df, lambda = seq(0, 1, len= 50))
plot(modrid$GCV)
modrid = lm.ridge(siri~. ,data = train_df, lambda = seq(0, 0.01, len= 50))
plot(modrid$GCV)
modrid = lm.ridge(siri~. ,data = train_df, lambda = seq(0, 0.1, len= 50))
plot(modrid$GCV)
which.min(modrid$GCV)
names(which.min(modrid$GCV))
as.numeric(names(which.min(modrid$GCV)))
library(lars)
install.packages('lars')
library(lars)
modlas = lars(as.matrix(train_df[,-1]), train_df$siri)
summary(modlas)
plot(modlas)
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri)
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri)
summary(modlas)
plot(modlas)
modlas$cv
modlas$index[which.min(modlas$cv)]
modlas
?cv.lars
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
modlas$index[which.min(modlas$cv)]
modlas
modlas = lars(as.matrix(train_df[,-1]), train_df$siri)
cvlas = cv.lars(as.matrix(train_df[,-1]), train_df$siri, plot.it = F)
optlam = modlas$index[which.min(modlas$cv)]
?lars
modlas
modlas$lambda
optlam
optlam = modlas$index[which.min(modlas$cv)]
optlam = cvlas$index[which.min(cvlas$cv)]
optlam
modf = lars(as.matrix(train_df[,-1]), train_df$siri, )
?predict.lars
predict(modlas, s= optlam, type = 'coef', mode = 'fraction')
coef = predict(modlas, s= optlam, type = 'coef', mode = 'fraction')
cvcoef = predict(modlas, s= optlam, type = 'coef', mode = 'fraction')
predict(moda, test_df)
predict(modb, test_df)
predict(modc, test_df)
predict(modc, test_df, ncomp = 7)
predict(modd, test_df)
predict(modd, test_df, ncomp = 4)
predict(mode, test_df)
mode = lm.ridge(siri~. , dat = train_df, lmabda = optlam)
predict(mode, test_df)
?lm.ridge
mode
mode
as.matrix(test_df[,-1])
as.matrix(test_df[,-1]) %*% mode
as.matrix(test_df[,-1]) %*% mode$coef
predict(modd, test_df, ncomp = 4)
as.matrix(test_df[,-1]) %*% mode$coef
mode$coef
mode
mode$Inter
coef(mode)
cbind(1,as.matrix(test_df[,-1])) %*%coef(mode)
modf = modlas
predict(modf, s = optlam, newx = as.matrix(test_df[,-1]))
predict.lars()
?predict.lars
predict(modf, s = optlam, newx = as.matrix(test_df[,]))
predict(modf, s = optlam, newx = as.matrix(test_df[,-1]))
test_df[,-1]
as.matrix(test_df[,-1])
predict(modf, s = optlam, newx = as.matrix(test_df[,-1]), mode = 'fraction')
y = test_df[,1]
mean((y-ya)^2)
ya = predict(moda, test_df)
yb = predict(modb, test_df)
yc = predict(modc, test_df, ncomp = 7)
yd = predict(modd, test_df, ncomp = 4)
ye = cbind(1,as.matrix(test_df[,-1])) %*%coef(mode)
yf = predict(modf, s = optlam, newx = as.matrix(test_df[,-1]), mode = 'fraction')
y = test_df[,1]
mean((y-ya)^2)
mean((y-yb)^2)
mean((y-yc)^2)
mean((y-yd)^2)
mean((y-ye)^2)
mean((y-yf)^2)
yf
yf = predict(modf, s = optlam, newx = as.matrix(test_df[,-1]), mode = 'fraction')$fit
)
mean((y-yf)^2)
mean((y-ya)^2)
mean((y-yb)^2)
mean((y-yc)^2)
mean((y-yd)^2)
mean((y-ye)^2)
mean((y-yf)^2)
ggplot(data = red) + geom_histogram(aes(x=total.sulfur.dioxide,
fill = as.factor(quality)))
library(tibble)
library(dplyr)
library(ggplot2)
summary(red)
setwd("~/")
### 0. Install libraries
#install.packages("leaps")
library(leaps)
### 0. Data Preprocessing
red <- read.csv("../data/winequality-red.csv", header = TRUE, sep = ";")
red[!complete.cases(red),]
library(tibble)
### 0. Install libraries
#install.packages("leaps")
library(leaps)
### 0. Data Preprocessing
red <- read.csv("../data/winequality-red.csv", header = TRUE, sep = ";")
setwd("~/GitHub/STOR664_Applied_Statistics/code")
### 0. Data Preprocessing
red <- read.csv("../data/winequality-red.csv", header = TRUE, sep = ";")
red[!complete.cases(red),]
library(tibble)
library(dplyr)
library(ggplot2)
summary(red)
varnames = colnames(red)
par(mfrow = c(3, 4))
for(name in varnames){
hist(red[[name]], main=name, xlab = NULL, ylab = NULL )
}
mean_summary = red %>% group_by(quality) %>% summarise_all(mean)
par(mfrow = c(3, 4))
for(name in varnames){
plot(mean_summary$quality,
mean_summary[[name]],
ylab = name
)
}
ggplot(data = red) + geom_histogram(aes(x=total.sulfur.dioxide,
fill = as.factor(quality)))
cor(red)
install.packages('corrplot')
library(corrplot)
corrplot(red)
colnames(red)
corrplot(red)
cor(red)
which(abs(cor(red)) > 0.5)
which(abs(cor(red)) > 0.7)
summary(lm_all)
logred = red
logred$logFA = log(red$fixed.acidity)
logred$logVA = log(red$volatile.acidity)
logred$logCA = red$citric.acid
logred$logRS = log(red$residual.sugar)
logred$logCL = log(red$chlorides)
logred$logFS = log(red$free.sulfur.dioxide)
logred$logTS = log(red$total.sulfur.dioxide)
logred$logDE = log(red$density)
logred$logPH = red$pH
logred$logSP = log(red$sulphates)
logred$logAL = log(red$alcohol)
lm_all = lm(quality ~., red)
lm_log = lm(quality~. , logred[,12:23])
AIC(lm_all)
AIC(lm_log)
df1 = logred[,1:12]
for(i in 1:11){
lm1 = lm(quality~., df1)
aic1 = AIC(lm1)
df2 = df1
df2[,i] = logred[12+i]
lm2 = lm(quality~., df2)
aic2 = AIC(lm2)
if(aic2<aic1){
df1 = df2
colname(df1)[i]
}
}
df1 = logred[,1:12]
for(i in 1:11){
lm1 = lm(quality~., df1)
aic1 = AIC(lm1)
df2 = df1
df2[,i] = logred[12+i]
lm2 = lm(quality~., df2)
aic2 = AIC(lm2)
if(aic2<aic1){
df1 = df2
}
}
df1
df1 = logred[,1:12]
for(i in 1:11){
lm1 = lm(quality~., df1)
aic1 = AIC(lm1)
df2 = df1
df2[,i] = logred[12+i]
lm2 = lm(quality~., df2)
aic2 = AIC(lm2)
if(aic2<aic1){
df1 = df2
print(paste0('switching ', i))
}
}
head(df1)
head(red)
df1 = logred[,1:12]
for(i in 1:11){
lm1 = lm(quality~., df1)
aic1 = AIC(lm1)
df2 = df1
df2[,i] = logred[12+i]
lm2 = lm(quality~., df2)
aic2 = AIC(lm2)
if(aic2<aic1){
df1 = df2
colnames(df1)[i] = colnames(df2)[i]
print(paste0('switching ', i))
}
}
df1
head(df1)
df1 = logred[,1:12]
for(i in 1:11){
lm1 = lm(quality~., df1)
aic1 = AIC(lm1)
df2 = df1
df2[,i] = logred[12+i]
colnames(df2)[i] = colnames(logred[12+i])
lm2 = lm(quality~., df2)
aic2 = AIC(lm2)
if(aic2<aic1){
df1 = df2
print(paste0('switching ', i))
}
}
head(df1)
df1 = logred[,1:12]
lm1 = lm(quality~., df1)
aic1 = AIC(lm1)
for(i in 1:11){
df2 = df1
df2[,i] = logred[12+i]
colnames(df2)[i] = colnames(logred[12+i])
lm2 = lm(quality~., df2)
aic2 = AIC(lm2)
if(aic2<aic1){
df1 = df2
lm1 = lm2
aic1 = aic2
print(paste0('switching ', i))
}
}
head(df1)
summary(lm1)
### 4. Variable Selection
lm_red <- lm(quality ~ ., df1)
summary(lm_red)
require(leaps)
b <- regsubsets(quality ~ ., df1)
rs <- summary(b)
par(mfrow = c(1, 3))
# AIC
rs$which
AIC <- nrow(red)*log(rs$rss/nrow(red)) + (2:9)*2
plot(AIC ~ I(1:8),
#main = "AIC",
ylab = 'AIC',
xlab = 'Number of Predictors', pch = 20)
text(I(1:8), AIC, round(AIC, 2), cex = 0.5, pos = 4)
# Adjusted R-Squre
plot(1:8, rs$adjr2,
xlab = 'Number of Predictors',
ylab='Adjusted R-Square', pch = 20)
which.max(rs$adjr2)
# Mellow's Cp
plot(2:9, rs$cp,
xlab = 'Number of Parameters',
ylab = 'Cp Statistic', pch = 20)
abline(0,1)
par(mfrow = c(1, 1))
install.packages('glmnet')
library(glmnet)
